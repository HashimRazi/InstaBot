{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction.\n",
    "### InstaBot - 1\n",
    "\n",
    "I have added sleeptime to an extent because of slow driver and to keep up with the driver, so it may take time to load and run another task.   \n",
    "There is also a copy file.  \n",
    "Make sure the connection is good :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Driver session and visiting Instagram.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path = r\"C:\\Users\\hashi\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")  \n",
    "driver.get('https://www.instagram.com/accounts/login/')\n",
    "time.sleep(16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Login To Instagram Handle\n",
    "\n",
    "To login into the Instagram, we need to first find the Textbox where we can type username and Password in it.  \n",
    "After that we need to find the submit button so that we can  click on  submit button to submit the username and password."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME,'username')))\n",
    "pw = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.NAME,'password')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "un.send_keys('SAMPLE USERNAME')\n",
    "time.sleep(2)\n",
    "pw.send_keys('SAMPLE PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = driver.find_element_by_xpath('//*[@id=\"loginForm\"]/div/div[3]/button')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.click()\n",
    "time.sleep(13)\n",
    "## add wait time here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding if we need to save login info or not, in our case we are not saving login info.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    not_now = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/main/div/div/div/div/button')))\n",
    "    not_now.click()\n",
    "    time.sleep(12)\n",
    "    not_now1 = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[4]/div/div/div/div[3]/button[2]')))\n",
    "    not_now1.click()\n",
    "    \n",
    "except (NoSuchElementException, TimeoutException, ElementNotInteractableException):\n",
    "    pass\n",
    "time.sleep(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There is an option for TURN ON NOTIFICATIONS when i logged in for first time, when i logged in for second time, it didnt appear, if it appears in your case, remove the comment and use it.\n",
    "### I have added the exception in that, you can leave it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##not_now1 = driver.find_element_by_xpath('/html/body/div[3]/div/div/div/div[3]/button[2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##not_now1.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Typing Food in Search bar and printing all the username.\n",
    "\n",
    "First step is to find the search box and then we need to pass the text 'food' in it.\n",
    "Then we need to do infinite scrolling with sleep time as 4 sec where we extract all the usernames in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    clear = WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "    clear.click()\n",
    "    search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "    search_box.send_keys('food')\n",
    "    time.sleep(9)\n",
    "    \n",
    "    \n",
    "except (NoSuchElementException, ElementNotInteractableException):\n",
    "    search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "    search_box.send_keys('food')\n",
    "    time.sleep(9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "sb = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME,'fuqBx')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we are appending username and acc link in dict as key value so that if the required account exists in dictionary, we can visit it optimally instead of searching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yourfoodlab\n",
      "foodrush.recipe\n",
      "food_food_surat\n",
      "foodie_incarnate\n",
      "sailusfood\n",
      "food_tales__\n",
      "food\n",
      "food52\n",
      "_____foodbaby\n",
      "mumbaifoodie\n",
      "pune_food_blogger\n",
      "saveourtummies\n",
      "___krittikaaa\n",
      "foodchoiceofmumbai\n",
      "foodinngarage\n",
      "foodfuly\n",
      "food.darzee\n",
      "food_with_a_foodie\n",
      "aahaa_emi_ruchi\n",
      "food_lunatic\n",
      "food_from_myrasoii\n",
      "thisisdelhi\n",
      "food.bydeep\n",
      "foodlinkcatering\n",
      "delhifoodwalks\n",
      "foodartproject\n",
      "whiteplatestories\n",
      "thehungrymumbaikar\n",
      "anime__food\n",
      "foodzeee\n",
      "foodys\n",
      "akshadagupta\n",
      "foodcapturecollective\n",
      "food__0__graphy\n",
      "foodtographyschool\n",
      "maneet_16\n",
      "rice__and__more\n",
      "foodies__forever\n",
      "foodstories_by_vaish\n",
      "mealplans\n",
      "foodmaniacindia\n",
      "consciousfoodindia\n",
      "thefoodbabe\n",
      "foodreliks\n",
      "meghnasfoodmagic\n",
      "goodfoodkitchenmumbai\n",
      "mumbaifoodcrush\n",
      "anna_janecka\n",
      "foodnetwork\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'yourfoodlab': 'https://www.instagram.com/yourfoodlab/',\n",
       " 'foodrush.recipe': 'https://www.instagram.com/foodrush.recipe/',\n",
       " 'food_food_surat': 'https://www.instagram.com/food_food_surat/',\n",
       " 'foodie_incarnate': 'https://www.instagram.com/foodie_incarnate/',\n",
       " 'sailusfood': 'https://www.instagram.com/sailusfood/',\n",
       " 'food_tales__': 'https://www.instagram.com/food_tales__/',\n",
       " 'food': 'https://www.instagram.com/food/',\n",
       " 'food52': 'https://www.instagram.com/food52/',\n",
       " '_____foodbaby': 'https://www.instagram.com/_____foodbaby/',\n",
       " 'mumbaifoodie': 'https://www.instagram.com/mumbaifoodie/',\n",
       " 'pune_food_blogger': 'https://www.instagram.com/pune_food_blogger/',\n",
       " 'saveourtummies': 'https://www.instagram.com/saveourtummies/',\n",
       " '___krittikaaa': 'https://www.instagram.com/___krittikaaa/',\n",
       " 'explore/tags/food': 'https://www.instagram.com/explore/tags/food/',\n",
       " 'foodchoiceofmumbai': 'https://www.instagram.com/foodchoiceofmumbai/',\n",
       " 'foodinngarage': 'https://www.instagram.com/foodinngarage/',\n",
       " 'foodfuly': 'https://www.instagram.com/foodfuly/',\n",
       " 'food.darzee': 'https://www.instagram.com/food.darzee/',\n",
       " 'food_with_a_foodie': 'https://www.instagram.com/food_with_a_foodie/',\n",
       " 'aahaa_emi_ruchi': 'https://www.instagram.com/aahaa_emi_ruchi/',\n",
       " 'food_lunatic': 'https://www.instagram.com/food_lunatic/',\n",
       " 'food_from_myrasoii': 'https://www.instagram.com/food_from_myrasoii/',\n",
       " 'thisisdelhi': 'https://www.instagram.com/thisisdelhi/',\n",
       " 'food.bydeep': 'https://www.instagram.com/food.bydeep/',\n",
       " 'foodlinkcatering': 'https://www.instagram.com/foodlinkcatering/',\n",
       " 'delhifoodwalks': 'https://www.instagram.com/delhifoodwalks/',\n",
       " 'foodartproject': 'https://www.instagram.com/foodartproject/',\n",
       " 'whiteplatestories': 'https://www.instagram.com/whiteplatestories/',\n",
       " 'thehungrymumbaikar': 'https://www.instagram.com/thehungrymumbaikar/',\n",
       " 'anime__food': 'https://www.instagram.com/anime__food/',\n",
       " 'foodzeee': 'https://www.instagram.com/foodzeee/',\n",
       " 'foodys': 'https://www.instagram.com/foodys/',\n",
       " 'akshadagupta': 'https://www.instagram.com/akshadagupta/',\n",
       " 'explore/tags/foodporn': 'https://www.instagram.com/explore/tags/foodporn/',\n",
       " 'foodcapturecollective': 'https://www.instagram.com/foodcapturecollective/',\n",
       " 'food__0__graphy': 'https://www.instagram.com/food__0__graphy/',\n",
       " 'foodtographyschool': 'https://www.instagram.com/foodtographyschool/',\n",
       " 'maneet_16': 'https://www.instagram.com/maneet_16/',\n",
       " 'rice__and__more': 'https://www.instagram.com/rice__and__more/',\n",
       " 'foodies__forever': 'https://www.instagram.com/foodies__forever/',\n",
       " 'foodstories_by_vaish': 'https://www.instagram.com/foodstories_by_vaish/',\n",
       " 'explore/tags/foodie': 'https://www.instagram.com/explore/tags/foodie/',\n",
       " 'mealplans': 'https://www.instagram.com/mealplans/',\n",
       " 'foodmaniacindia': 'https://www.instagram.com/foodmaniacindia/',\n",
       " 'consciousfoodindia': 'https://www.instagram.com/consciousfoodindia/',\n",
       " 'thefoodbabe': 'https://www.instagram.com/thefoodbabe/',\n",
       " 'explore/locations/214159357/phoenix-marketcity-mumbai': 'https://www.instagram.com/explore/locations/214159357/phoenix-marketcity-mumbai/',\n",
       " 'explore/tags/foodblogger': 'https://www.instagram.com/explore/tags/foodblogger/',\n",
       " 'foodreliks': 'https://www.instagram.com/foodreliks/',\n",
       " 'meghnasfoodmagic': 'https://www.instagram.com/meghnasfoodmagic/',\n",
       " 'goodfoodkitchenmumbai': 'https://www.instagram.com/goodfoodkitchenmumbai/',\n",
       " 'mumbaifoodcrush': 'https://www.instagram.com/mumbaifoodcrush/',\n",
       " 'anna_janecka': 'https://www.instagram.com/anna_janecka/',\n",
       " 'explore/locations/221255893/food-inn-lokhandwala': 'https://www.instagram.com/explore/locations/221255893/food-inn-lokhandwala/',\n",
       " 'foodnetwork': 'https://www.instagram.com/foodnetwork/',\n",
       " 'explore/tags/foodphotography': 'https://www.instagram.com/explore/tags/foodphotography/'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = []\n",
    "d = {}\n",
    "for i in driver.find_elements_by_xpath('//a[@class = \"-qQT3\"]/div/div[2]/div/div/div/div'):\n",
    "    arr.append(i.text)\n",
    "    \n",
    "for j in driver.find_elements_by_xpath('//a[@class = \"-qQT3\"]'):\n",
    "    x = j.get_attribute('href')\n",
    "    y = j.get_attribute('href')[26:-1]\n",
    "    d[y] = x\n",
    "    \n",
    "\n",
    "for i in arr:\n",
    "    if i != '':\n",
    "        print(i)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "## text attribute is used to print the text inside the tags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Searching and Opening Profile of account 'So Delhi'\n",
    "\n",
    "To do that, we need to do the following steps\n",
    "First search the dict, if key exists, we visit it via link, else   \n",
    "1. Clear the Searchbox\n",
    "2. Type sodelhi in Search box\n",
    "3. Search for account.\n",
    "4. If account appears, click on that account.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//div[contains(@class, \"coreSpriteSearchClear\")]')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear.click()\n",
    "time.sleep(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    driver.get(d['sodelhi'])\n",
    "    \n",
    "    \n",
    "except KeyError:\n",
    "    try:\n",
    "        clear = WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "        clear.click()\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('sodelhi')\n",
    "        time.sleep(6)\n",
    "        acc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a')))\n",
    "        acc.click()\n",
    "        time.sleep(9)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('sodelhi')\n",
    "        time.sleep(6)\n",
    "        acc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a')))\n",
    "        acc.click()\n",
    "        time.sleep(9)\n",
    "\n",
    "## Im adding sleep time after every send_keys because the driver is taking time in loading the elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Follow/ Unfollow given handle\n",
    "\n",
    "To Do that, we need to First find the follow button, and then click on it.  \n",
    "To unfollow, we need to click the follow button again, where it shows unfollow button, then we need to click on that.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/div[1]/div[1]/div/div/div/span/span[1]/button')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've followed the account!\n"
     ]
    }
   ],
   "source": [
    "if follow.get_attribute('innerHTML') == 'Follow':\n",
    "    follow.click()\n",
    "    print(\"You've followed the account!\")\n",
    "else:\n",
    "    print(\"You're already following the account!\")\n",
    "time.sleep(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've Unfollowed the Account!\n"
     ]
    }
   ],
   "source": [
    "## unfollowing the account.\n",
    "\n",
    "if follow.get_attribute('innerHTML') != 'Follow':\n",
    "    follow.click()\n",
    "    time.sleep(7)\n",
    "    unfollow = driver.find_element_by_xpath('/html/body/div[5]/div/div/div/div[3]/button[1]')\n",
    "    unfollow.click()\n",
    "    print(\"You've Unfollowed the Account!\")\n",
    "else:\n",
    "    print(\"You've already unfollowed the account!\")\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Like/ Unlike Post of the account 'dilsefoodie'\n",
    "\n",
    "1. To like/dislike the first 30 post of dilsefoodie, we first need to serch the account 'dilsefoodie' in dict.\n",
    "   If it exist, we visit it using the acc link, else we search it manually.\n",
    "2. Then we have to click on that account.\n",
    "3. After clicking on that account, we need to first click on the post.\n",
    "4. Then find the like button and click on it.\n",
    "5. Then find the next post button, click on it.\n",
    "6. Repeat this cycle 30 times.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.get(d['dilsefoodie'])\n",
    "    \n",
    "except KeyError:\n",
    "    try:\n",
    "        clear = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "        clear.click()\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('dilsefoodie')\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a'))).click()\n",
    "        time.sleep(5)\n",
    "    \n",
    "    \n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('dilsefoodie')\n",
    "        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a'))).click()\n",
    "        time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach:  \n",
    "The Page structure of the IG Profile Page(May change if youre reading this because I faced few issues where I have to copy   \n",
    "the xpath of the few buttons because they were not working or maybe due to STALEELEMENTEXCEPTION) is that it has post in   \n",
    "grids.  \n",
    "If we hover over the post, it will show two options on video one is Play and other is comment, so to like the post,     \n",
    "we need to first click over the post and then like the post and then move to next page.    \n",
    "  \n",
    " \n",
    "1. So the step is to first click on the post, like it and then move to next.  \n",
    "2. Now as we move to next page, we need to use a loop where we need to run that loop 29 times.  \n",
    "3. On the IG page, in svg tag, it has attribute 'aria-label' which shows whether post is liked or not.   \n",
    "4. So first we check if the post is liked or not, 'Like' attribute means post is not liked.  \n",
    "5. So to find the svg element, we use Explicit wait where we first find the svg element and then we check.  \n",
    "6. If it is True, we find the like button using explicit wait, and then like the post and then using explicit wait,  \n",
    "   we find the next page link and click on it and repeat it 29 times.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liked 30 Posts\n"
     ]
    }
   ],
   "source": [
    "post = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/div[3]/article/div[1]/div/div[1]/div[1]/a/div[1]/div[2]')))\n",
    "post.click()\n",
    "time.sleep(5)\n",
    "like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "like.click()\n",
    "next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a')))\n",
    "next.click()\n",
    "time.sleep(5)\n",
    "\n",
    "i = 0\n",
    "while i != 30:\n",
    "    svg = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"QBdPU \"]/span/*[name() = \"svg\"]')))\n",
    "    if svg.get_attribute('aria-label') == 'Like':\n",
    "        like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "        like.click()\n",
    "        time.sleep(4)\n",
    "        next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "        next.click()\n",
    "        time.sleep(4)\n",
    "    else:\n",
    "        next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "        next.click()\n",
    "        time.sleep(4)\n",
    "\n",
    "        \n",
    "    i += 1\n",
    "    if i == 29:    ## i == 29 because we have already liked 1 post before starting of this loop\n",
    "        print('Liked 30 Posts')\n",
    "\n",
    "        \n",
    "        \n",
    "close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/button')))\n",
    "close.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unliked 30 Posts\n"
     ]
    }
   ],
   "source": [
    "## Unliking the posts\n",
    "## using try catch here so that driver runs smoothly.\n",
    "## Runs on same logic as liking the post\n",
    "\n",
    "\n",
    "try:\n",
    "    close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/button')))\n",
    "    close.click()\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    post = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/div[3]/article/div[1]/div/div[1]/div[1]/a/div[1]/div[2]')))\n",
    "    post.click()\n",
    "    time.sleep(5)\n",
    "    like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "    like.click()\n",
    "    next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a')))\n",
    "    next.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    i = 0\n",
    "    while i != 31:\n",
    "        svg = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"QBdPU \"]/span/*[name() = \"svg\"]')))\n",
    "        if svg.get_attribute('aria-label') == 'Unlike':\n",
    "            like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "            like.click()\n",
    "            time.sleep(4)\n",
    "            next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "            next.click()\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "            next.click()\n",
    "            time.sleep(4)\n",
    "        i += 1\n",
    "        if i == 30:\n",
    "            print('Unliked 30 Posts')\n",
    "\n",
    "    close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/button')))\n",
    "    close.click()\n",
    "    \n",
    "    \n",
    "    \n",
    "except TimeoutException:\n",
    "    \n",
    "\n",
    "    post = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/div[3]/article/div[1]/div/div[1]/div[1]/a/div[1]/div[2]')))\n",
    "    post.click()\n",
    "    time.sleep(4)\n",
    "    like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "    like.click()\n",
    "    next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a')))\n",
    "    next.click()\n",
    "    time.sleep(4)\n",
    "\n",
    "    i = 0\n",
    "    while i != 30:\n",
    "        svg = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//div[@class = \"QBdPU \"]/span/*[name() = \"svg\"]')))\n",
    "        if svg.get_attribute('aria-label') == 'Unlike':\n",
    "            like = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[2]/div/article/div[3]/section[1]/span[1]/button/div/span')))\n",
    "            like.click()\n",
    "            time.sleep(4)\n",
    "            next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "            next.click()\n",
    "            time.sleep(4)\n",
    "        else:\n",
    "            next = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[1]/div/div/a[2]')))\n",
    "            next.click()\n",
    "            time.sleep(4)\n",
    "        i += 1\n",
    "        if i == 29:\n",
    "            print('Unliked 30 Posts')\n",
    "\n",
    "    close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div[3]/button')))\n",
    "    close.click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Extract List of Followers\n",
    "\n",
    "### Extracting followers of 'sodelhi'\n",
    "\n",
    "Extracting first 500 followers of the page 'foodtalkindia' and 'sodelhi'.  \n",
    "We check the dict if key exists or not if it exist, we visit the account by the link, else:  \n",
    "First Step is to Search the account.   \n",
    "Then Click on the account.  \n",
    "Then click on followers.  \n",
    "Extract the followers name.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.get(d['sodelhi'])\n",
    "\n",
    "except KeyError:\n",
    "    try:\n",
    "        clear = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "        clear.click()\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('sodelhi')\n",
    "        time.sleep(2)\n",
    "        un = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div')))\n",
    "        un.click()\n",
    "        time.sleep(9)\n",
    "    \n",
    "    \n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('sodelhi')\n",
    "        time.sleep(2)\n",
    "        un = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div')))\n",
    "        un.click()\n",
    "        time.sleep(9)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[2]/a')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers.click()\n",
    "time.sleep(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "followerslist = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[2]/ul')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 36 48 60 72 84 96 108 120 132 144 156 168 180 192 204 216 228 240 252 264 276 288 300 312 324 336 348 360 372 384 396 408 420 432 444 456 468 480 492 504 "
     ]
    }
   ],
   "source": [
    "followerslist = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[2]/ul')))\n",
    "\n",
    "driver.execute_script('arguments[0].scrollIntoView(0, 1);', followerslist)\n",
    "cur = driver.execute_script('return document.body.scrollHeight;')\n",
    "\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    un = driver.find_elements_by_xpath('/html/body/div[5]/div/div/div[2]/ul/div/li')\n",
    "    time.sleep(8)\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0, 500);', followerslist)   ## concept\n",
    "    time.sleep(4)\n",
    "    print(len(un), end = ' ')   ## This will tell the amount of followers fetched in one scroll(Depends on how \n",
    "                                ## good our connection is)Also the scroll will take time.\n",
    "    if len(un) >= 500:\n",
    "        break\n",
    "    i+=1\n",
    "  \n",
    " \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 500 Followers of 'sodelhi' : \n",
      "---------------------------------------------------------------------------\n",
      "manishajayswal7\n",
      "sonaliv1215\n",
      "jonathan134413\n",
      "ramandeep_sethi\n",
      "_ballu_0625\n",
      "shahed_kreshan\n",
      "yettobevet_\n",
      "rammodwel\n",
      "deepanshhu\n",
      "sachitjolly\n",
      "anurag__kapoor\n",
      "minhajur_raahman\n",
      "shaurya.gupta.12\n",
      "ashu_somal\n",
      "imkonark\n",
      "kaumudi_joshi\n",
      "khushi.chawla.54922\n",
      "prachi_mukund\n",
      "fly2parikshit\n",
      "aarushi_514\n",
      "chughnikunj\n",
      "creativewords_power\n",
      "_aryandhawle_\n",
      "amitchoudhary002\n",
      "dr.akanksha_m43\n",
      "sa_tya7748\n",
      "kanishq_basoya_dellhii0001\n",
      "kumarvibha\n",
      "vipinllb\n",
      "itssatyam_garg\n",
      "shivanibhilwaray\n",
      "focosbytaran\n",
      "raviiik\n",
      "batra_akhil\n",
      "nishantmudgil123\n",
      "sanzeev_k_paswan\n",
      "nishitjindal09\n",
      "ammu8.248\n",
      "unknownbadiee\n",
      "dj.arie5\n",
      "sakshilicious_19\n",
      "pattysinp\n",
      "rahullsingh_19\n",
      "aryansinghal99\n",
      "timba909\n",
      "aabhishekgg\n",
      "issa_me_yash\n",
      "mansi_00120012\n",
      "jetinkashyap\n",
      "nitin.k14\n",
      "jasmeenkaur_505\n",
      "vanshhsehgall\n",
      "sassymuskaan\n",
      "smritisneha5781\n",
      "nitichouhan___\n",
      "aakusachdeva\n",
      "mayankmonga01\n",
      "deepanshugoel10\n",
      "jordysbarwhisky\n",
      "drhardikmehta_titanium_\n",
      "_._.ave\n",
      "tapishpahil_01\n",
      "morning_star09\n",
      "flamming_nights\n",
      "pragneeshkapoor\n",
      "sangeetprasana\n",
      "kajal.kri14\n",
      "adsharma25297\n",
      "santosh.dhangar.16144606\n",
      "itsrahulbose\n",
      "ajit_mirgane_\n",
      "yadav_abhy\n",
      "shimlameraki\n",
      "vdixit_08\n",
      "pulkitkapoor011\n",
      "rajnisharmagill\n",
      "veeraj_sabarwal\n",
      "kraftgallore\n",
      "chaujer09\n",
      "reddy7724\n",
      "mr.arslan.malik_1.4.3\n",
      "laughyesslaugh\n",
      "champagne1__lassi\n",
      "bhavesh1107\n",
      "vijaykumarpatel9128\n",
      "dakshmittal1\n",
      "rishijindal111\n",
      "call.me.bhukkad.bunny\n",
      "top_trackerr\n",
      "ankit_ambis\n",
      "vats_sham\n",
      "devkhandelwal12344\n",
      "deep_rao__\n",
      "rama_0y\n",
      "travistas.india\n",
      "shivanimadaan65\n",
      "_r_devil_\n",
      "gurkanwalbenipal\n",
      "manishsam\n",
      "_siddhant.prabhakar_\n",
      "mansi_vrx\n",
      "prajeshsurwase1234\n",
      "ishanii.mukherjee\n",
      "yummekdumm\n",
      "ranshul_sharma\n",
      "bittusohal\n",
      "satbirrajchauhan\n",
      "sabby__shah\n",
      "rishu_rishu_001\n",
      "aakhileshbhardwaj\n",
      "monstr720\n",
      "joyesh_\n",
      "alpha786153\n",
      "kh.ambika\n",
      "riya_sejwal28\n",
      "shaurriyaofficial\n",
      "tancymoira\n",
      "amanchaudhary19\n",
      "beyourownv\n",
      "ananya.r2621\n",
      "rishi_xarma_vix\n",
      "medinutrica.healthcare\n",
      "shobhi.t\n",
      "ankita_manot\n",
      "artsclub21\n",
      "satdubey93\n",
      "niharika_pathak96\n",
      "agrawal08payal\n",
      "_smurfacc_\n",
      "swatitheo\n",
      "__aryamansingh\n",
      "i_amshubh\n",
      "harshillicious_1997\n",
      "mokshi5838_\n",
      "dhawan.juhi\n",
      "_promethean._16\n",
      "keerthi__yadav__\n",
      "_____abhisxek_____\n",
      "srishhtayyy\n",
      "piyush_agarwal_1100\n",
      "rishabhjain505\n",
      "gauravarora55\n",
      "simrann.chugh\n",
      "cajatinsachdeva\n",
      "megha_seth_\n",
      "aditya__puri\n",
      "puja.gupta31\n",
      "paras_mahajan05\n",
      "_rajput__nayan__rana_\n",
      "dhrisha_hegde_offical\n",
      "ankit.heisenberg\n",
      "ant.nature\n",
      "panch_parmeshwar\n",
      "origin_nitss\n",
      "armaan.gupta.9028\n",
      "_upen.dra\n",
      "nitinyadavansi13_\n",
      "barkharohilla\n",
      "moonchild_12_\n",
      "curly_girl_nisha\n",
      "s.kamtrewal\n",
      "dewan_sahaab\n",
      "huzaifabharmal44\n",
      "iamhamzapatell\n",
      "new_reet\n",
      "jasneetsiingh\n",
      "tamanuppal\n",
      "s.prashanthsagar\n",
      "garimagoel97\n",
      "yours_harsh_rajput\n",
      "ankitnegi1996\n",
      "rudransh111\n",
      "bunny_singh96\n",
      "11nikitagupta\n",
      "manish._.rajput_06\n",
      "pihu_lama\n",
      "jo_.bwoyyyy\n",
      "yajat.dhawan\n",
      "_.prayrna\n",
      "amodh_sehgal\n",
      "manvi_sehgal\n",
      "anshii.rc\n",
      "avaneesh1003\n",
      "whateven1_1\n",
      "kunalchadha395\n",
      "aforalien___\n",
      "illest.pvt\n",
      "suyashiagarwalll\n",
      "rahul_srivastava1611\n",
      "imanavrathore\n",
      "kashish0023\n",
      "sunainaaaa___\n",
      "roshan.choudhary.376\n",
      "yaarmihir\n",
      "ushanain1111\n",
      "ishikamehlawatt\n",
      "gurnoor_kohli\n",
      "sayam_jain24\n",
      "eddysharma_\n",
      "preetarora1313\n",
      "mns_meghna\n",
      "avanti.agrawal\n",
      "priyesh_pandit\n",
      "leaf_it.to.me\n",
      "shivamyam\n",
      "manishsaifisaifi\n",
      "girl_gaming_22\n",
      "holdmawater\n",
      "shauryarya\n",
      "manishagoyalofficial\n",
      "karmanyamarwah08\n",
      "divyaaamishraaa\n",
      "sunakshigupta\n",
      "siddy_7059\n",
      "anu_anuutty_\n",
      "incredibleboy_ashu\n",
      "artsy_hands_pari\n",
      "kritikamanak\n",
      "lakshay0607\n",
      "kiranrsnair\n",
      "_chubbyy_girl__\n",
      "agra_live_\n",
      "rick.x40v20t30\n",
      "sushainbhargava\n",
      "vasavi.kadiyala\n",
      "harshal.adya\n",
      "akku_1703\n",
      "imvineetkapoor\n",
      "nikhil_solankhi\n",
      "nikeeta006\n",
      "arushiaggarwalll\n",
      "shrey.pajarolibre\n",
      "joshideepanshu\n",
      "jnehamillennial\n",
      "music_vision_fitness\n",
      "livewithdivi\n",
      "pratikp.pvt\n",
      "masala_paneer\n",
      "ridhimarastogi_18\n",
      "shafana_salman\n",
      "rohan.saldanha\n",
      "iti_3\n",
      "siddhesh_sao\n",
      "shubhi_joon\n",
      "thesarcasticbeardo\n",
      "naina_thakur_1\n",
      "kabirashamadhusudan\n",
      "amarjeetins\n",
      "zed_4_zayn\n",
      "_deep_writes_\n",
      "aparnathipremgiri\n",
      "vibhutisharmaaa\n",
      "deoprabinkumar\n",
      "hardevsingh.k92\n",
      "akhandewale\n",
      "nisha_9_03\n",
      "0_.kingelf_0\n",
      "iam_ifra_khan\n",
      "eveandweds\n",
      "satwika234\n",
      "uttrardhi_singh\n",
      "dheerajverma1\n",
      "sa.gar143\n",
      "cinematicclickstudio\n",
      "rasina_razzaq\n",
      "hemantk17\n",
      "sac662\n",
      "harmandhillon261015\n",
      "_ownthestreets_\n",
      "awalktohorizon\n",
      "mr.rishabhjain\n",
      "sapnarstg07\n",
      "cuteboy_v_i_v_e_k\n",
      "its_piyush.5911\n",
      "kim_not_plausible\n",
      "dixittt_10\n",
      "kashish_minocha\n",
      "i_trouvaille001\n",
      "akanksha_matta\n",
      "the.rich.indian.culture\n",
      "gora_uppal_786\n",
      "sirswaggamuffin\n",
      "jamatia.saslang\n",
      "lazy_panda_i_am\n",
      "mrinmayyi\n",
      "ausgabecraftwork\n",
      "computer_ai_\n",
      "palak_sharma3573\n",
      "amyvibes__\n",
      "dainamatw\n",
      "shrutiiichhabra1512\n",
      "imharmanp\n",
      "__tusharkumar__\n",
      "itsteeeeee\n",
      "explorendia\n",
      "iamanilbisht__\n",
      "pchohan71\n",
      "iaishwarya_rawat\n",
      "yogendra_sastry\n",
      "wolf_prhmx\n",
      "dessertery.in\n",
      "kuchankahibaatein2021\n",
      "comefeelme5561\n",
      "amrutha_hasini\n",
      "nilotpal_majumder\n",
      "h_s_gaming526\n",
      "samrath_kr018singh\n",
      "ma_nshi7133\n",
      "neha_aishu_\n",
      "sreejithkarumanaghat\n",
      "eman.alrisheq92\n",
      "mr_food_corner24\n",
      "parthrathoree\n",
      "_ruhuchauhan_\n",
      "lx_rajesh10\n",
      "kgf__furkan\n",
      "ana.sali4372\n",
      "gambhir30\n",
      "iamanchaudhary\n",
      "prabhh05\n",
      "sumitphogatofficial\n",
      "milen_fitocosmetica\n",
      "jjchaudharyhere123\n",
      "chauhan.kshitij\n",
      "shraddhaa9999\n",
      "abhishekmaurya912\n",
      "gonzamaryori\n",
      "aterek_beauty\n",
      "_ahan.na._\n",
      "grace_mosha1\n",
      "gucci_407\n",
      "samad._tiger02\n",
      "richa.019\n",
      "0mor.ality\n",
      "aadyaarora__\n",
      "aarzoo.chauhan\n",
      "the_.wandering._feet\n",
      "nehagupta9209\n",
      "sojamnapaar\n",
      "rasmikaur\n",
      "neha_patel_818\n",
      "pragyaagnihotri\n",
      "1vishal_kr\n",
      "piyush.garg530\n",
      "gopaljikecholebhature\n",
      "shrey.abaranwal\n",
      "flywings57\n",
      "_sheena.bhatia_\n",
      "prakriti_sri\n",
      "kunning__king021\n",
      "tabbukezaike\n",
      "samridhi687\n",
      "mehjabin6520\n",
      "_hydrategym_\n",
      "shabana_khan1037\n",
      "theravielectronics\n",
      "i_bk_daiya7\n",
      "sukhpreetkaurss\n",
      "aaishadiarieskw\n",
      "aryankumar0209\n",
      "food__travel__unlimited\n",
      "ananyasinghrajput_\n",
      "rishabh_2096\n",
      "jindal__sanskar\n",
      "kaif21082001\n",
      "no_username_was_accessible\n",
      "hrideyy\n",
      "__.mohit_.____\n",
      "riyadhawan\n",
      "yash.r.paliwal\n",
      "aashutoshdash\n",
      "injailoutsooooooooon\n",
      "mudimath\n",
      "prajakta103\n",
      "boss_king_420\n",
      "pinchofyum27\n",
      "world_photo77\n",
      "vaidmohit2010\n",
      "jyoology\n",
      "sabanayabkhaan\n",
      "suni_panku\n",
      "ankursingh457\n",
      "home_fit_official\n",
      "sakshiabhihanda\n",
      "official_om_1000\n",
      "yara_correia2\n",
      "insta.monikaarora\n",
      "meghacreative\n",
      "vijaymolpariya\n",
      "foodieelife_29\n",
      "meeradileesh\n",
      "gopalkrishantiwari1\n",
      "sindhusrighakollapu\n",
      "dead.dealll\n",
      "foodie_on_a_roll_\n",
      "dhruviiiiiiiiiiiiiii\n",
      "jenn1234soul\n",
      "cute_boy7071\n",
      "space6_baby\n",
      "roshankumar_off\n",
      "hybe_entmt\n",
      "shwta_ydv\n",
      "amit__modak2.0\n",
      "gunjansood2021\n",
      "abdesslem.gr\n",
      "_allthingstravel_\n",
      "irahul11\n",
      "narinder_ral\n",
      "_kanikananda\n",
      "mr.pukar_10\n",
      "kataria31051\n",
      "leonilinda23\n",
      "yashjain15\n",
      "manjarisingh.91\n",
      "aruna_2289\n",
      "sudheer_97\n",
      "omprakash8178991995\n",
      "rashi_ag13\n",
      "chandaanandanchan\n",
      "surjyot.7\n",
      "pulakchaturvedi\n",
      "bhamrasunita\n",
      "balrajsingh41\n",
      "knavs.knavs.knavs\n",
      "the_name_of_shine25\n",
      "theindianbridess\n",
      "shiny_girl_70\n",
      "iampurushotam\n",
      "gunjan_desai_gd\n",
      "aahilya_as\n",
      "swetakujur1111\n",
      "i_am_aroosh_zaki\n",
      "saiakanshya\n",
      "pranavelectricalelectronic\n",
      "_brown_bull_\n",
      "01_.d.o.r.a.e.m.o.n._\n",
      "the.fmj\n",
      "prakash__aditya\n",
      "sameer.pvt69\n",
      "nik_hil_gandhi\n",
      "kumar560123\n",
      "earthisbeautiful5\n",
      "_prateek_pvt_\n",
      "doodlemysoul\n",
      "akkusharma75\n",
      "karnatakpreeti\n",
      "devil_the_morningstar\n",
      "saksham_saluja\n",
      "geetanshipal\n",
      "ayantika7274\n",
      "ankita_kalyani0707\n",
      "thukral.k\n",
      "simpy_yadav_27\n",
      "rachitgoel01\n",
      "yaarjigriiii\n",
      "2141pearl\n",
      "create.click\n",
      "a_n_i_r_u_d_h_24_\n",
      "itsme.shiv_\n",
      "jos.pantry\n",
      "iiww022\n",
      "colleen_fashion_\n",
      "divadumonde6\n",
      "imd_raj\n",
      "shreajain\n",
      "rosadilkhush\n",
      "viibbbhhhhaaaaa\n",
      "reshmataneja9\n",
      "snemu97\n",
      "anubha87\n",
      "surbhi_choubey\n",
      "i_vinit_singh\n",
      "ali_miqdad\n",
      "baesicallyjazz\n",
      "shoryakhera_1406\n",
      "blessygorgeous1111\n",
      "drinkwatermannat\n",
      "dulcet_foods\n",
      "ogaabdelgawad\n",
      "saloniverma__\n",
      "meen.akshi9146\n",
      "rum_yeah_\n",
      "shwetasharma7598\n",
      "l_a_k_2005\n",
      "bhardwajvivek000\n",
      "veena.2215\n",
      "64abhijeet64\n",
      "saad_orhan\n",
      "harnoorcantsingh\n",
      "nishh_anth_shetty\n",
      "dishaennerjeet\n",
      "_duttareya_\n",
      "singh_gurdaatt\n",
      "swapeco\n",
      "ig.lix_gaming\n",
      "beezbuzzing\n",
      "ny_2146\n",
      "official.gurjinder.sidhu\n",
      "sana_yadav_28\n",
      "sarcastic._.quotes365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "arr = []\n",
    "j =  0\n",
    "for i in un:\n",
    "    a = BeautifulSoup(i.get_attribute('outerHTML'), 'html.parser')\n",
    "    b = a.a['href'][1:-1]\n",
    "    arr.append(b)\n",
    "    j+=1\n",
    "    if j == 500:\n",
    "        break\n",
    "print(\"List of \"+str(len(arr))+\" Followers of 'sodelhi' : \")\n",
    "print('---------------------------------------------------------------------------')\n",
    "for i in arr:\n",
    "    print(i)\n",
    "    \n",
    "close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[2]/button')))\n",
    "\n",
    "close.click()\n",
    "time.sleep(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, to find 500 followers of account 'foodtalkindia', we need to follow the foll steps.  \n",
    "We first check it on the dictionary, if the key exists, we will visit the page by the link, else  \n",
    "1. Find the searchbox and type sodelhi in it and open the account.  \n",
    "2. click on the followers list and follow the exact same step as above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    driver.get(d['foodtalkindia'])\n",
    "\n",
    "except KeyError:\n",
    "    try:\n",
    "        clear = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "        clear.click()\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('foodtalkindia')\n",
    "        time.sleep(2)\n",
    "        acc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div')))\n",
    "        acc.click()\n",
    "        time.sleep(10)\n",
    "    \n",
    "    \n",
    "    except (NoSuchElementException, ElementNotInteractableException):\n",
    "        search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "        search_box.send_keys('foodtalkindia')\n",
    "        time.sleep(2)\n",
    "        acc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a/div')))\n",
    "\n",
    "        acc.click()\n",
    "        time.sleep(10)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 36 48 60 72 84 96 108 120 132 144 156 168 180 192 204 216 228 240 252 264 276 288 300 312 324 336 348 360 372 384 396 408 420 432 444 456 468 480 492 504 "
     ]
    }
   ],
   "source": [
    "followerslist = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[2]/a')))\n",
    "followerslist.click()\n",
    "\n",
    "listscroll =  WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[5]/div/div/div[2]/ul')))\n",
    "\n",
    "driver.execute_script('arguments[0].scrollIntoView(0, 1);', listscroll)\n",
    "\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    user = driver.find_elements_by_xpath('/html/body/div[5]/div/div/div[2]/ul/div/li')\n",
    "    time.sleep(4)\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0, 500);', listscroll)\n",
    "    time.sleep(4)\n",
    "    print(len(user), end = ' ')\n",
    "    if len(user) >= 500:\n",
    "        break\n",
    "    i+=1\n",
    "  \n",
    " \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 500 Followers of account 'foodtalkindia' : \n",
      "---------------------------------------------------------------------------\n",
      "__mfmt\n",
      "__bikektm\n",
      "jadhavjayati\n",
      "s_k_singh_patel\n",
      "sammed98_aug\n",
      "tarannumsbutterhalf\n",
      "shivanand_avati\n",
      "sanskari_______bitch\n",
      "_abhishekbanerjee_\n",
      "jordysbarwhisky\n",
      "joh.nnyhawaii\n",
      "_the_delhi_foodie\n",
      "shivamgandhi26\n",
      "bestinindia01\n",
      "sris__kitchen__21\n",
      "indian.cafes\n",
      "sunidhisingh10\n",
      "prajeshsurwase1234\n",
      "nikhilyadav005\n",
      "sagar_______king\n",
      "monstr720\n",
      "brownsugar_indirapuram\n",
      "sashalalchandani\n",
      "tgb_____cake\n",
      "moody_artisogram\n",
      "shalini.bhattar\n",
      "_its_parna_\n",
      "hiteshganch\n",
      "harshit.mehta18\n",
      "x_nancy._9514\n",
      "incredibleboy_ashu\n",
      "seema_5152\n",
      "shwets.yadav2011\n",
      "jatin.upreti.359\n",
      "amr_foods\n",
      "karan__malhotra9\n",
      "dipikachowhan\n",
      "neha_bajaj78\n",
      "rasadouthana\n",
      "awalktohorizon\n",
      "tushar_pokharkar98\n",
      "p_i_y_u__sh143\n",
      "computer_ai_\n",
      "avanillabean04\n",
      "foodie__fellow\n",
      "viraajsisodiya\n",
      "kuchankahibaatein2021\n",
      "hexaglobal.official\n",
      "chopraprer89\n",
      "alka_sharma\n",
      "anikkhalak\n",
      "mr_food_corner24\n",
      "nupurtandon\n",
      "heenansharma\n",
      "indus_19\n",
      "astro_nawreen_522\n",
      "sonalgupta_05\n",
      "coachdeepa\n",
      "varun_paliwal\n",
      "ritik_kr56\n",
      "samnew175\n",
      "nath_78280\n",
      "panky2906\n",
      "trulymadlyfoodie\n",
      "tanu_5875\n",
      "aswin9309\n",
      "bhagyashreeofficialaccount\n",
      "reetusaxsena5566\n",
      "warda_ka_kitchen\n",
      "adwaysvhsjsnn\n",
      "harshitasharma021\n",
      "cake_story_111\n",
      "sushmita__shukla\n",
      "rajan_palai\n",
      "1368__rani\n",
      "delicious_1000\n",
      "anu_u13\n",
      "amitjhuraney\n",
      "singhanushruti\n",
      "bake.stories\n",
      "anjalirasiwasia\n",
      "mava_mamtavani\n",
      "foodieelife_29\n",
      "gulshankumar_0_3\n",
      "foodie_war08\n",
      "gotowanie_jest_proste_\n",
      "laura_nutritionist\n",
      "pachayappan0215\n",
      "__sarah_wu__\n",
      "_kanikananda\n",
      "juidey2000\n",
      "akanchhay\n",
      "thechocochuckle\n",
      "sagarsuri29\n",
      "paulalorani\n",
      "_myfoodstoriess_\n",
      "mystery_flavors9990\n",
      "officialdeepak12345\n",
      "kumar560123\n",
      "abhinai8\n",
      "misskaurmakeup\n",
      "fiestafinedine\n",
      "urj.aaa\n",
      "sumedhajaggi\n",
      "yinna.008\n",
      "nithish_kumar_j_\n",
      "anubha87\n",
      "rukayyah_hussayn\n",
      "mehjabeen_gungun\n",
      "ritakar1\n",
      "arjunsarsrarjunsarsr\n",
      "kamalpreet1441\n",
      "mmy_nd_kitchen\n",
      "official.gurjinder.sidhu\n",
      "cocoabykay\n",
      "anjaliswap\n",
      "saumye.k\n",
      "shashank87goel\n",
      "bitehealthycalories\n",
      "aayesha23_g\n",
      "shrikantpatro\n",
      "class_of_yum22\n",
      "rohit885348\n",
      "naba_worklove\n",
      "pracritik\n",
      "wine_cocktail_more\n",
      "mr.sidd.56\n",
      "siddhantkhanna06\n",
      "ofcours319\n",
      "diksha_singh_rana\n",
      "pastryandpies\n",
      "food_science_techno\n",
      "vinsazkitchen\n",
      "miauyeda\n",
      "__food.cravings__\n",
      "tossiemommy\n",
      "_sweta_\n",
      "punjabisunabh\n",
      "tomatino_101\n",
      "srushti098\n",
      "rhymyhsn362\n",
      "inikitarathod\n",
      "alpinerhapsody\n",
      "mobile_photography_10_24\n",
      "theforkandspoonlovestory2020\n",
      "dr.eams3268\n",
      "muke.sh528\n",
      "its_yadav04\n",
      "monday2sundayrasoi\n",
      "24x7goodfood\n",
      "nimtalentna\n",
      "hitankdryfruits\n",
      "fizza_agha_\n",
      "sweet_tradition7\n",
      "hezretaly2004\n",
      "christofer_frantzis\n",
      "springhouse.cowork\n",
      "s_m_a_r_t_b_o_i\n",
      "its_sarang_jassmanak\n",
      "chatkara.swaad.ka\n",
      "vkbeats143\n",
      "thefoodcanvas_\n",
      "tarunraja144\n",
      "gurmeet_786_\n",
      "life.of_v_\n",
      "coco_merchant_007\n",
      "juneja.anshul\n",
      "prasantshindhe\n",
      "15ad_bakery\n",
      "tanejaaparna\n",
      "fit_foodie.official\n",
      "honey_babe89\n",
      "pallavi_sharma16\n",
      "aali.ya6404\n",
      "the_naughty_boy_ashwin_s_\n",
      "mr._tosif07\n",
      "foodz_evything\n",
      "maahir.suresh\n",
      "priya1270gupta\n",
      "pooh.parvati\n",
      "_.peaceful_.boy\n",
      "marymanomy_thomas\n",
      "1_more_dream\n",
      "king_official_31\n",
      "desifusiontasteofnorth\n",
      "mtalabe_dost\n",
      "shrutiinsaree\n",
      "outlookdoodle_official\n",
      "_sugar__fix_\n",
      "kunal_sharma3059\n",
      "eshapandey07\n",
      "peace_fighter_for_life\n",
      "4324_kamal\n",
      "akshaygowdakr11\n",
      "kartik8805\n",
      "rajiv.frank\n",
      "k_a_v_y_5779\n",
      "shiv.johar\n",
      "geetu2406\n",
      "clothbeautybyr\n",
      "the_arya_tripathi\n",
      "peelchopstir\n",
      "kevisdario\n",
      "drivwanders\n",
      "ha.snain7428\n",
      "jassi__duggal\n",
      "amitdhalla07\n",
      "uncommonlifeq\n",
      "hukhe_aala_mandal\n",
      "chandrika0558\n",
      "mymyt3233\n",
      "ravan_0900\n",
      "tangytrails\n",
      "sarathkumar3771\n",
      "tealentils\n",
      "shweta_mystery24\n",
      "shraddha_salunkhe02\n",
      "design_art_arkkitects\n",
      "nilofer.e\n",
      "foodies.farm\n",
      "raghuveerkc\n",
      "akashgupta2008\n",
      "foodographybyvipin\n",
      "virsanyal\n",
      "ayeshascreation2020\n",
      "iamsahilmirza21\n",
      "mclandiea\n",
      "foodiethefoodlover\n",
      "vickyghodke1\n",
      "foodhilighter\n",
      "ashishmathur8\n",
      "herbsandhubs\n",
      "swati1mehra\n",
      "mohit_chaurasiaa\n",
      "quickreachmedia\n",
      "lord_vaddr\n",
      "suraj___mandal888\n",
      "shankaronfire12\n",
      "meetovermeal\n",
      "indefinite_skyy\n",
      "pihupawar102\n",
      "technicalworldsc\n",
      "official.rajput.boy.s\n",
      "areejrao81\n",
      "aarti_954\n",
      "sunshine_97258\n",
      "khalsacreation12\n",
      "naina_rajgaria\n",
      "kowinz\n",
      "letsgokhaiba\n",
      "rekhakalaria\n",
      "meme.game69\n",
      "treats_of_life\n",
      "gunraaj2018\n",
      "nitinrajput8448\n",
      "y.c2505\n",
      "_chef_amrya_khan\n",
      "__prince_keddy__\n",
      "rajku.mar7934\n",
      "anny20040305\n",
      "mothersbiryaniindia\n",
      "anime.editz256\n",
      "tahrim_iraqui\n",
      "sanjaycrockeryhouse\n",
      "_arihant_finance_\n",
      "deepak.soren.3194\n",
      "urbanlifestyle.in\n",
      "globalchaskaavc\n",
      "cook_o_graphy\n",
      "jaideep_ankur\n",
      "aaweblog\n",
      "rohitondiet\n",
      "i_m_gaurav_sharmaa\n",
      "bakewithakki04\n",
      "criteria2\n",
      "al_bismillah_biriyani\n",
      "aviva_163\n",
      "ik417840\n",
      "sweetboy1795\n",
      "sharma_komila\n",
      "shivalingnaik\n",
      "new_account_he\n",
      "daredevil.1964\n",
      "research_0_\n",
      "sonifoodedit\n",
      "tweakyourpalate\n",
      "sr.monit\n",
      "deepali.tonde\n",
      "shraddha.kumbhani\n",
      "deeptsharma799\n",
      "mumbaiseafoodwala\n",
      "_kingshubham_\n",
      "neuropsycquanta\n",
      "sulthana5544\n",
      "siddharthrelhan\n",
      "himanshisaini505\n",
      "deepthipricilla\n",
      "srishticelebration2013\n",
      "ch_etan_786\n",
      "culinarydelights85\n",
      "shinsangki\n",
      "raji_sekar3\n",
      "vora.kaushik_09\n",
      "divi.0901\n",
      "shashi_sareen\n",
      "_ghar_ka__khana\n",
      "caumedghazi\n",
      "aradhna8\n",
      "sugery___plum\n",
      "thind_ibothu\n",
      "sahilbhateja13\n",
      "offcial217\n",
      "angrymamaswok\n",
      "svadfoods\n",
      "namexx___\n",
      "status._.reels\n",
      "yaduvanshicharliepvt\n",
      "foodstories_by_np\n",
      "boby_2236\n",
      "sv.8436\n",
      "hungrychefgirl\n",
      "pinkukhansmaajsevii\n",
      "avishikochhar\n",
      "deny_8144\n",
      "thekotian_\n",
      "sonam__bajwa1\n",
      "mylocaltales\n",
      "ahir_se_panga_nahi\n",
      "ranjanasrivastava32\n",
      "fab_cakes01\n",
      "la.lala5661\n",
      "pritikhanna13\n",
      "_taste_of_happiness_\n",
      "mf_o05\n",
      "divya6527\n",
      "saiwagh302\n",
      "madeeha.smile\n",
      "asha_groups\n",
      "the_actual_siddharathsehdev\n",
      "shonaliacharya\n",
      "raja___khodal_\n",
      "fashionlogodesign\n",
      "zappy16\n",
      "tanivalecha\n",
      "foodislove_37\n",
      "hungryborn034\n",
      "malkeynass\n",
      "aman_raj_1432\n",
      "rajachamu\n",
      "amisha66801\n",
      "nanu_sethi_tandan\n",
      "devanshi__bhatia\n",
      "mafiyabhai780\n",
      "makeup_._by_._sanjana\n",
      "sourabh.kumar.39566\n",
      "sw.apna8765\n",
      "askgarima\n",
      "its_mee_8582\n",
      "cookly.bookly.bhoox\n",
      "shahnawaz862017\n",
      "luxurycars9807\n",
      "bushra.9876\n",
      "decor_decoration345\n",
      "af.bush.ra\n",
      "mypepperstart\n",
      "sathikkapoorsathikkapoor\n",
      "explore.beautyof.india\n",
      "srid_harkrissh\n",
      "stininsta69\n",
      "iamma00\n",
      "swami2193\n",
      "mengaltaiyab\n",
      "thebrowniegurl\n",
      "dastarkhan_legacy\n",
      "gautam_jain1432\n",
      "devishaksingh\n",
      "_ro_hit_24k_\n",
      "i_.am._pooja\n",
      "honeyja9\n",
      "damyanti52patel\n",
      "_the_foodies_world_7\n",
      "tushaar17\n",
      "eshwar_.traveller\n",
      "rahul_godarasaab29\n",
      "rage_quiters47\n",
      "_vaibhav__raj_\n",
      "iamsumitdatta\n",
      "srivastava774\n",
      "itz_sameer_275\n",
      "evorootz\n",
      "padmavengatesh\n",
      "cattoishungry\n",
      "simendodhia\n",
      "its_shivanksinghal\n",
      "anitha.annie989\n",
      "monika_bubby_1209\n",
      "bujjiselvan\n",
      "rohitbawa553\n",
      "jiyo__khusise\n",
      "barkhachiya\n",
      "smriti0807\n",
      "asatisagar369\n",
      "randomsamosa\n",
      "ganeshshinde8373\n",
      "sonyaulakh459\n",
      "ds9696104\n",
      "chef_samirgiri\n",
      "stark_mark_50_85\n",
      "manpreet_singh_sodhis\n",
      "pawansharmasss\n",
      "grishmahemani\n",
      "rare_blood_boy_\n",
      "myrendezvouswithfood\n",
      "gudapati.surendra\n",
      "nikitashinde2432\n",
      "thespicechart\n",
      "hdfoods_06\n",
      "jorie.bazaar\n",
      "vikrant10v\n",
      "croscerc\n",
      "__sk__ayu__04596\n",
      "silentknight1432\n",
      "cutiepie_3_4\n",
      "_smart_pp\n",
      "foodie_tune_indore\n",
      "101pruthvi\n",
      "shanmugi_m\n",
      "_suhailt\n",
      "renukamanish\n",
      "sura.jsingh3452\n",
      "diksha_mishra03\n",
      "aishu__o4\n",
      "ruhan1579\n",
      "desaihirald\n",
      "rishika_uboveja\n",
      "nikita_singha_03\n",
      "adityapandeylove\n",
      "aritri4\n",
      "doc.rajatpal\n",
      "just.lil.extra\n",
      "surbhisharma1649\n",
      "rezomozmen\n",
      "ankushyadav6340\n",
      "nationalcargomoverspvtltd\n",
      "91.13584204\n",
      "brain_storm.16\n",
      "keepingupwarya\n",
      "ph.uong220904\n",
      "_ty_l_er_1708\n",
      "universal_foodie_\n",
      "kirtivermakhurana\n",
      "chillkaroyaar\n",
      "hariharanasha\n",
      "foodieabhisek\n",
      "handcraftedgourmet\n",
      "ofsaltgrains\n",
      "roshinishomemade\n",
      "sonalichopra\n",
      "foodarthospitality\n",
      "overripestories\n",
      "sweetyparakh\n",
      "bhartichawla.mua\n",
      "swapandebnath165\n",
      "fouziyamudasir\n",
      "thelazy_gourmet\n",
      "cxz__9087\n",
      "vijayagram\n",
      "shirishtip\n",
      "s.rozmin26\n",
      "ssk_salik\n",
      "dk151346\n",
      "justforeignyasss\n",
      "princesharma_1213\n",
      "sandie_rt\n",
      "the_popping_tummy\n",
      "sk_food_court\n",
      "shenoyleena\n",
      "deepakarora423\n",
      "dhriti_ghosh_\n",
      "ravatsandeep69\n",
      "aadilrazzi\n",
      "_sammys_foodblog_\n",
      "sagar_mishra3633\n",
      "the_cake_desire_s\n",
      "hafsashahid800\n",
      "tamizh_ramesh\n",
      "tserin_\n",
      "itsuchihaitachi_\n",
      "sunilmadan\n",
      "foodiee_stan\n",
      "ravar_vishal268\n",
      "jivika_goenka\n",
      "coooking_vlog\n",
      "amipunitharsur\n",
      "desitadka_tadka\n",
      "tonicandtoasties\n",
      "matheysh5\n",
      "loveking2405\n",
      "official_zain.7\n",
      "im_neits\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "foodtalkindia = []\n",
    "j =  0\n",
    "for i in user:\n",
    "    a = BeautifulSoup(i.get_attribute('outerHTML'), 'html.parser')\n",
    "    b = a.a['href'][1:-1]\n",
    "    foodtalkindia.append(b)\n",
    "    j+=1\n",
    "    if j == 500:\n",
    "        break\n",
    "print(\"List of \"+str(len(arr))+\" Followers of account 'foodtalkindia' : \")\n",
    "print('---------------------------------------------------------------------------')\n",
    "for i in foodtalkindia:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[2]/button')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "close.click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Printing all the followers of 'foodtalkindia' that you are following but those who dont follow you.\n",
    "To do that, we need to do the following steps.\n",
    "1. First we extract the followers and following list of our account.  \n",
    " a. To find the no of followers, we use the same logic as we used to fetch the followers of foodtalkindia.  \n",
    " b. But instead of scrolling 500 times, we will scroll for no of followers and following in our account.  \n",
    "2. Then we find out the unfollowers that we follow, but they dont follow you.\n",
    "3. Then we need to find the followers which are in unfollowers list and in foodtalkindia followers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clicking on profile option\n",
    "p = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/div[5]/span')))\n",
    "p.click()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clicking on profile\n",
    "p1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/div[5]/div[2]/div[2]/div[2]/a[1]')))\n",
    "p1.click()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting Number of followers of users account.\n",
    "\n",
    "followercount = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[2]/a/span')))\n",
    "s = followercount.get_attribute('title')\n",
    "try:\n",
    "    s = int(s) \n",
    "                    \n",
    "except ValueError:\n",
    "    s = s.replace(',','').strip()\n",
    "    s = int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "followers = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[2]/a')))\n",
    "followers.click()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class = 'isgrP']/ul\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 24 "
     ]
    }
   ],
   "source": [
    "## fetching Followers\n",
    "\n",
    "driver.execute_script('arguments[0].scrollIntoView(0, 1);', scroll)\n",
    "\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    user = driver.find_elements_by_xpath('/html/body/div[5]/div/div/div[2]/ul/div/li')\n",
    "    time.sleep(2)\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0, 500);', scroll)\n",
    "    time.sleep(2)\n",
    "    print(len(user), end = ' ')\n",
    "    if len(user) == s:     ## running loop till no of following times.\n",
    "        break\n",
    "    i+=1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting Followers\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "myfollowers = []\n",
    "j =  0\n",
    "for i in user:\n",
    "    a = BeautifulSoup(i.get_attribute('outerHTML'), 'html.parser')\n",
    "    \n",
    "    b = a.a['href'][1:-1]\n",
    "    myfollowers.append(b)\n",
    "\n",
    "    j+=1\n",
    "    if j == s:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[2]/button')))\n",
    "\n",
    "close.click()\n",
    "time.sleep(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now fetching no of  following.\n",
    "\n",
    "\n",
    "nofoll = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[3]/a/span')))\n",
    "s1 = nofoll.text\n",
    "try:\n",
    "    s1 = int(s1)\n",
    "except ValueError:\n",
    "    s1 = s1.replace(',','').strip()\n",
    "    s1 = int(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "following = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/section/ul/li[3]/a')))\n",
    "following.click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scroll1 = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//div[@class = 'isgrP']/ul\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 24 36 48 60 72 84 96 108 120 132 144 156 161 "
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while True:\n",
    "    user1 = driver.find_elements_by_xpath('/html/body/div[5]/div/div/div[2]/ul/div/li')\n",
    "    time.sleep(2)\n",
    "    driver.execute_script('arguments[0].scrollIntoView(0, 500);', scroll1)\n",
    "    time.sleep(2)\n",
    "    print(len(user1), end = ' ')\n",
    "    if len(user1) == s1:    ## Running loop till no of following times\n",
    "        break\n",
    "    i+=1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "myfollowing = []\n",
    "j =  0\n",
    "for i in user1:\n",
    "    a = BeautifulSoup(i.get_attribute('outerHTML'), 'html.parser')\n",
    "    \n",
    "    b = a.a['href'][1:-1]\n",
    "    myfollowing.append(b)\n",
    "\n",
    "    j+=1\n",
    "    if len(user1) == s:\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '/html/body/div[5]/div/div/div[1]/div/div[2]/button')))\n",
    "\n",
    "close.click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "following = set(myfollowing)\n",
    "myfollowers = set(myfollowers)\n",
    "foodtalkindia = set(foodtalkindia)\n",
    "\n",
    "\n",
    "## now finding people who does not follow us\n",
    "\n",
    "unfollowers = following.difference(myfollowers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mutual Followers\n"
     ]
    }
   ],
   "source": [
    "## Now to find the followers of foodtalkindia that you are following but those who dont follow you, we need\n",
    "## to find the intersection between unfollowers and foodtalkindia.\n",
    "\n",
    "mutualfollowers = unfollowers.intersection(foodtalkindia)\n",
    "\n",
    "if len(mutualfollowers) == 0:\n",
    "    print('No mutual Followers')\n",
    "else:\n",
    "    print('Mutual followers are: ')\n",
    "    for i in mutualfollowers:\n",
    "        print(i)\n",
    "        \n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check the story of 'coding.ninjas'\n",
    "\n",
    "\n",
    "To see the story, we need to first find the profile \n",
    "Then find the Profile Pic, Then click on it.  \n",
    "To check whether the accout has added the story, we need to inspect.  \n",
    "     \n",
    "After inspection, I found that The Validation for whether story is added is in some div tag where it has attribute 'aria-disabled'.    \n",
    "If the attribute is 'true', it means it has no story.  \n",
    "If attribute is 'false', the story is available and there is condition.  \n",
    "1. In the profile pic, there is an attribute 'height' and 'width', when THERE IS STORY IS AVAILABLE AND NOT VIEWED, size of        profile pic is 210.  \n",
    "2. If the STORY IS AVAILABLE AND IS VIEWED, size of the profile pic is 208.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    clear = WebDriverWait(driver, 1).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[2]')))\n",
    "    clear.click()\n",
    "    search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "    search_box.send_keys('coding.ninjas')\n",
    "    \n",
    "    \n",
    "except (NoSuchElementException, ElementNotInteractableException):\n",
    "    search_box = WebDriverWait(driver, 100).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/input')))\n",
    "    search_box.send_keys('coding.ninjas')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[2]/div[3]/div/div[2]/div/div[1]/a')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc.click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "story = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/div/div')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the story\n",
      "Viewing the Story, check the driver \n"
     ]
    }
   ],
   "source": [
    "if story.get_attribute('aria-disabled') == 'true':\n",
    "    print('Account has not added any story')\n",
    "elif story.get_attribute('aria-disabled') == 'false':\n",
    "    height = driver.find_element_by_xpath('//*[@id=\"react-root\"]/section/main/div/header/div/div/canvas')\n",
    "    if height.get_attribute('height') == '208':\n",
    "        print(\"You've seen the story\")\n",
    "    elif height.get_attribute('height') == '210':\n",
    "        print(\"View the story\")\n",
    "        print(\"Viewing the Story, check the driver \")\n",
    "        storyclick = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/main/div/header/div/div')))\n",
    "        storyclick.click()\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged Out\n"
     ]
    }
   ],
   "source": [
    "## logging out \n",
    "\n",
    "p = WebDriverWait(driver, 1000000).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/div[5]/span')))\n",
    "p.click()\n",
    "\n",
    "logout = WebDriverWait(driver, 1000).until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"react-root\"]/section/nav/div[2]/div/div/div[3]/div/div[5]/div[2]/div[2]/div[2]/div[2]')))\n",
    "logout.click()\n",
    "print('Logged Out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
